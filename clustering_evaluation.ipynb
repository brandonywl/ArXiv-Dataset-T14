{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a6ab6b-bdf8-473a-a993-1c76ea873a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:33:10.758562Z",
     "start_time": "2024-04-16T07:33:09.302702Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering evaluation using Rand Index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75537e7fecaa8dbe"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43c1458-0b5e-4687-b274-822c373863d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:33:10.785073Z",
     "start_time": "2024-04-16T07:33:10.651882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation function with an example\n",
    "# the truths are the list of arxiv categories for each paper, the preds are the cluster labels\n",
    "# rand score modified to allow for multiple categories per paper\n",
    "\n",
    "def modified_rand_score_vectorized(preds, truths):\n",
    "    n = len(preds)\n",
    "    \n",
    "    # Convert predictions to a numpy array for faster operations\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    # Prepare a label presence matrix\n",
    "    unique_labels = sorted(set(label for sublist in truths for label in sublist))\n",
    "    label_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    \n",
    "    # Create a boolean matrix of size (n, number of unique labels)\n",
    "    truth_matrix = np.zeros((n, len(unique_labels)), dtype=bool)\n",
    "    for i, labels in enumerate(truths):\n",
    "        truth_matrix[i, [label_index[label] for label in labels]] = True\n",
    "    \n",
    "    # Calculate pairwise matrix indicating shared label (the slowest part of the function))\n",
    "    shared_label_matrix = np.dot(truth_matrix, truth_matrix.T) > 0\n",
    "    \n",
    "    # Calculate pairwise equal predictions\n",
    "    same_pred = preds[:, None] == preds\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN using vectorized operations\n",
    "    TP = np.sum(np.logical_and(shared_label_matrix, same_pred))\n",
    "    TN = np.sum(np.logical_and(~shared_label_matrix, ~same_pred))\n",
    "    FP = np.sum(np.logical_and(~shared_label_matrix, same_pred))\n",
    "    FN = np.sum(np.logical_and(shared_label_matrix, ~same_pred))\n",
    "\n",
    "    # Correct for self-comparison (diagonal counts as True in both shared_label_matrix and same_pred)\n",
    "    TP -= n\n",
    "    \n",
    "    # Calculate the Rand Index\n",
    "    rand_index = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    return rand_index\n",
    "\n",
    "# Example usage\n",
    "preds = [1, 1, 2, 2]\n",
    "truths = [['a', 'b'], ['a'], ['c'], ['c', 'd']]\n",
    "print(modified_rand_score_vectorized(preds, truths))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Example usage with arxiv data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a663ed9cb6a3341"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function to add back the list of categories for each paper\n",
    "def reorg_category_df(df_categories):\n",
    "    data_ids, data_categories = [], []\n",
    "    cur_id, cat = \"\", []\n",
    "    data = df_categories.sort_values(\"id\")\n",
    "\n",
    "    for _, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        if cur_id != row[0]:\n",
    "            # save the exising id's categories data to dictionary. if cur_id is \"\", it indicates the beginning of the loop, no prior records to save\n",
    "            if cur_id != \"\":\n",
    "                data_ids.append(cur_id)\n",
    "                data_categories.append(\",\".join(cat))\n",
    "                cur_id = row[0]\n",
    "                cat = []\n",
    "            else:\n",
    "                cur_id = row[0]\n",
    "        cat.append(row[1])\n",
    "\n",
    "    df = pd.DataFrame.from_dict({\"id\": data_ids, 'categories': data_categories})\n",
    "    # save it to csv, so you could load it next time without rerunning\n",
    "    # df.to_csv(save_to_file_name)\n",
    "    # print(f\"Total {df.shape[0]} records. Have saved the file {save_to_file_name} into the data folder.\")\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T07:33:10.841448Z",
     "start_time": "2024-04-16T07:33:10.664077Z"
    }
   },
   "id": "63ccd8db59feafc2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4156055/4156055 [01:20<00:00, 51853.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# the data/arxiv-metadata-ext-category.csv file contains N rows of the same paper (same paper id) with N different categories\n",
    "df_categories = pd.read_csv(\"data/arxiv-metadata-ext-category.csv\",dtype={\"id\":object,\"category_id\":object})\n",
    "# Reorganize to each row as one paper with a column containing the list of categories. Might take 1 to 3+ mins.\n",
    "df_reorg_category = reorg_category_df(df_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T07:34:36.806243Z",
     "start_time": "2024-04-16T07:33:10.673644Z"
    }
   },
   "id": "a1824196c8f2b8a6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the clustering results with at least two columns: id and kmeans_label\n",
    "df_clustering = pd.read_csv(\"data/bertopic-kmeans60.csv\",dtype={\"id\":object})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:09:07.121009Z",
     "start_time": "2024-04-16T09:09:07.076229Z"
    }
   },
   "id": "5f490810c4bb2bf8",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_clustering = df_clustering.merge(df_reorg_category, how='left', on=\"id\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:09:08.414402Z",
     "start_time": "2024-04-16T09:09:07.510781Z"
    }
   },
   "id": "a6f64488d79aa50c",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                    id  topic_id  \\\n0        gr-qc/0209061        11   \n1        q-bio/0607018        36   \n2        q-bio/0604024        50   \n3        q-bio/0403036        36   \n4        q-bio/0610017        44   \n...                ...       ...   \n74384   hep-th/0602072         0   \n74385  hep-lat/0505005        31   \n74386  hep-lat/0308005        19   \n74387  hep-lat/0307015        19   \n74388  hep-lat/0004007        19   \n\n                                              categories  \n0                                   gr-qc,cs.CC,quant-ph  \n1      q-bio.GN,cs.IT,math-ph,math.IT,math.MP,physics...  \n2                        q-bio.PE,cs.CE,math.GR,q-bio.OT  \n3                       q-bio.GN,cs.CE,q-bio.BM,quant-ph  \n4                           q-bio.BM,cs.CG,cs.DM,math.MG  \n...                                                  ...  \n74384                                       cs.CC,hep-th  \n74385                      hep-lat,cs.CE,physics.comp-ph  \n74386                                      hep-lat,cs.DC  \n74387                                      hep-lat,cs.DC  \n74388                physics.comp-ph,cs.MS,hep-lat,cs.DC  \n\n[74389 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>topic_id</th>\n      <th>categories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gr-qc/0209061</td>\n      <td>11</td>\n      <td>gr-qc,cs.CC,quant-ph</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>q-bio/0607018</td>\n      <td>36</td>\n      <td>q-bio.GN,cs.IT,math-ph,math.IT,math.MP,physics...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>q-bio/0604024</td>\n      <td>50</td>\n      <td>q-bio.PE,cs.CE,math.GR,q-bio.OT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>q-bio/0403036</td>\n      <td>36</td>\n      <td>q-bio.GN,cs.CE,q-bio.BM,quant-ph</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>q-bio/0610017</td>\n      <td>44</td>\n      <td>q-bio.BM,cs.CG,cs.DM,math.MG</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74384</th>\n      <td>hep-th/0602072</td>\n      <td>0</td>\n      <td>cs.CC,hep-th</td>\n    </tr>\n    <tr>\n      <th>74385</th>\n      <td>hep-lat/0505005</td>\n      <td>31</td>\n      <td>hep-lat,cs.CE,physics.comp-ph</td>\n    </tr>\n    <tr>\n      <th>74386</th>\n      <td>hep-lat/0308005</td>\n      <td>19</td>\n      <td>hep-lat,cs.DC</td>\n    </tr>\n    <tr>\n      <th>74387</th>\n      <td>hep-lat/0307015</td>\n      <td>19</td>\n      <td>hep-lat,cs.DC</td>\n    </tr>\n    <tr>\n      <th>74388</th>\n      <td>hep-lat/0004007</td>\n      <td>19</td>\n      <td>physics.comp-ph,cs.MS,hep-lat,cs.DC</td>\n    </tr>\n  </tbody>\n</table>\n<p>74389 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clustering"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:09:08.425043Z",
     "start_time": "2024-04-16T09:09:08.414597Z"
    }
   },
   "id": "16d853a4969e4633",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1fd822e-bab9-4c2f-a5c5-f3bc973a5b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T09:09:08.426074Z",
     "start_time": "2024-04-16T09:09:08.419406Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_comma(input):\n",
    "    try:\n",
    "        return input.split(\",\")\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cfcb513-553e-4e14-8a5e-72d02259d125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T09:09:08.482216Z",
     "start_time": "2024-04-16T09:09:08.424116Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clustering[\"categories_list\"] = df_clustering[\"categories\"].apply(lambda x: split_comma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6de7405e-8422-4ab9-a43f-4fb3c7883c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T09:10:53.980900Z",
     "start_time": "2024-04-16T09:09:16.533847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0, score: 0.8510759675967596\n",
      "seed: 1, score: 0.8498602260226022\n",
      "seed: 2, score: 0.848571097109711\n",
      "seed: 3, score: 0.8514113811381138\n",
      "seed: 4, score: 0.8496474647464747\n",
      "seed: 5, score: 0.8532257625762576\n",
      "seed: 6, score: 0.8506539853985399\n",
      "seed: 7, score: 0.8492895089508951\n",
      "seed: 8, score: 0.8505053305330533\n",
      "seed: 9, score: 0.8485082308230824\n",
      "Average Rand Index Score: 0.8502748954895489\n"
     ]
    }
   ],
   "source": [
    "output_score = []\n",
    "# to speed up the evaluation, we sample random 10,000 papers 10 times and evaluate the clustering results based on the average score\n",
    "for i in range(10):\n",
    "    df_clustering_filter = df_clustering[~df_clustering[\"categories\"].isna()]\n",
    "    df_sample = df_clustering_filter.sample(10000, random_state = i)\n",
    "    #score = modified_rand_score_vectorized(df_sample[\"kmeans_label\"], df_sample[\"categories_list\"])\n",
    "    score = modified_rand_score_vectorized(df_sample[\"topic_id\"], df_sample[\"categories_list\"])\n",
    "    output_score.append(score)\n",
    "    print(f\"seed: {i}, score: {score}\")\n",
    "    \n",
    "print(f\"Average Rand Index Score: {np.mean(output_score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering evaluation using Silhouette Score (if possible)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a919526606277e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# X is a feature array and labels are predicted labels for each sample\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "# silhouette_score(X, labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad9fdb3ef365113"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
